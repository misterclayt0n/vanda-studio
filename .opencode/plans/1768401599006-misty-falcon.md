# Image Editing Conversations Feature

## Overview

Allow users to start a conversation from any generated image, iteratively edit it with natural language prompts, and generate new images across multiple turns. Each turn can use multiple models, and the conversation history is fully persisted.

---

## User Flow

### 1. Entry Point
- **Edit button** appears on hover over each generated image thumbnail
- Clicking opens the **Start Editing Modal**

### 2. Start Editing Modal (new conversation)
- Shows source image with model name + dimensions
- **Model selector** (multi-select) - defaults to source image's model but user can choose any
- **Text input** for describing the edit
- **Add references** button for additional reference images
- **"Start Editing" button** â†’ creates conversation, navigates to `/posts/edit/[conversationId]`

### 3. Conversation Page
- **Header**: Back button (â† Gallery), title (auto-generated from first prompt), turn count
- **Thumbnail strip**: Horizontal scroll of ALL images in conversation
- **Main area**: Conversation turns, each showing:
  - User message
  - Generated images (one per model, with loading skeletons for pending)
- **Input area**: Model selector + textarea + references button + send button
- **Progressive loading**: Images appear as they complete (subscription-based)

### 4. Reference Image Behavior
- **Automatic**: Previous turn's output images automatically become references for next turn
- **Manual additions**: User can add extra reference images per turn

---

## Schema Design

### New Tables

```typescript
// Image edit conversations
image_edit_conversations: defineTable({
    // Owner (can be any user who starts the conversation)
    userId: v.id("users"),
    
    // Source image that started this conversation
    sourceImageId: v.id("generated_images"),
    sourceStorageId: v.id("_storage"), // Denormalized for quick access
    
    // Metadata
    title: v.string(), // Auto-generated from first prompt
    
    // Settings (defaults for new turns)
    aspectRatio: v.string(), // Inherited from source
    resolution: v.string(),  // Inherited from source
    
    // Timestamps
    createdAt: v.number(),
    updatedAt: v.number(),
}).index("by_user_id", ["userId"])
  .index("by_source_image", ["sourceImageId"]),

// Each turn in a conversation
image_edit_turns: defineTable({
    conversationId: v.id("image_edit_conversations"),
    turnIndex: v.number(), // 0, 1, 2, ...
    
    // User input
    userMessage: v.string(),
    selectedModels: v.array(v.string()), // Models chosen for this turn
    
    // Additional reference images (user-uploaded)
    manualReferenceIds: v.optional(v.array(v.id("_storage"))),
    
    // Generation state (for progressive loading)
    status: v.string(), // "pending" | "generating" | "completed" | "error"
    pendingModels: v.optional(v.array(v.string())), // Models still generating
    
    createdAt: v.number(),
}).index("by_conversation", ["conversationId"])
  .index("by_conversation_turn", ["conversationId", "turnIndex"]),

// Output images for each turn (one per model)
image_edit_outputs: defineTable({
    turnId: v.id("image_edit_turns"),
    conversationId: v.id("image_edit_conversations"), // Denormalized for queries
    
    // Image data
    storageId: v.id("_storage"),
    model: v.string(),
    prompt: v.string(), // The prompt used
    width: v.number(),
    height: v.number(),
    
    createdAt: v.number(),
}).index("by_turn", ["turnId"])
  .index("by_conversation", ["conversationId"]),
```

---

## Backend Implementation

### File Structure

```
src/convex/
  imageEditConversations.ts  # Conversation CRUD
  imageEditTurns.ts          # Turn CRUD + progressive loading mutations
  imageEditOutputs.ts        # Output image queries
  ai/
    imageEdit.ts             # Actions: startConversation, sendEdit
```

### 1. `imageEditConversations.ts`

```typescript
// Queries
get(id)                    // Get single conversation with source image URL
listByUser()               // List all conversations for current user
getBySourceImage(imageId)  // Check if conversation exists for an image

// Mutations
create({ sourceImageId, title, aspectRatio, resolution })
updateTitle({ id, title })
remove({ id })             // Delete conversation + all turns + outputs
```

### 2. `imageEditTurns.ts`

```typescript
// Queries
listByConversation(conversationId)  // Get all turns with their outputs

// Mutations (public)
// None - turns are created by actions

// Internal Mutations (for actions)
internal.create({ conversationId, turnIndex, userMessage, selectedModels, manualReferenceIds })
internal.updateStatus({ id, status, pendingModels })
internal.removeFromPending({ id, model })  // Progressive loading
```

### 3. `imageEditOutputs.ts`

```typescript
// Queries
listByTurn(turnId)                  // Get outputs for a turn (with URLs)
listByConversation(conversationId)  // Get all outputs (for thumbnail strip)

// Internal Mutations
internal.create({ turnId, conversationId, storageId, model, prompt, width, height })
```

### 4. `ai/imageEdit.ts` (Actions)

#### `startConversation`

```typescript
export const startConversation = action({
    args: {
        sourceImageId: v.id("generated_images"),
        userMessage: v.string(),
        selectedModels: v.array(v.string()),
        manualReferenceIds: v.optional(v.array(v.id("_storage"))),
    },
    handler: async (ctx, args) => {
        // 1. Auth check
        // 2. Get source image data
        // 3. Create conversation with auto-generated title
        // 4. Create turn 0 with status "generating"
        // 5. Get source image URL as reference
        // 6. Generate images in parallel (one per model)
        //    - Each completion: save output, remove from pendingModels
        // 7. Mark turn as "completed"
        // 8. Return conversationId
    },
});
```

#### `sendEdit`

```typescript
export const sendEdit = action({
    args: {
        conversationId: v.id("image_edit_conversations"),
        userMessage: v.string(),
        selectedModels: v.array(v.string()),
        manualReferenceIds: v.optional(v.array(v.id("_storage"))),
    },
    handler: async (ctx, args) => {
        // 1. Auth check
        // 2. Get conversation
        // 3. Get previous turn's outputs (auto-references)
        // 4. Create new turn with next turnIndex
        // 5. Build reference URLs: previous outputs + manual references
        // 6. Generate images in parallel
        // 7. Mark turn as "completed"
        // 8. Update conversation.updatedAt
    },
});
```

**Key: Progressive Loading Pattern** (same as current post creation)

```typescript
await Promise.all(
    selectedModels.map(async (model) => {
        try {
            const result = await generateImage({
                caption: "", // Not needed for edits
                instructions: userMessage,
                referenceImageUrls,
                model,
                aspectRatio,
                resolution,
            });
            
            // Store image
            const storageId = await ctx.storage.store(blob);
            
            // Save output (triggers subscription)
            await ctx.runMutation(internal.imageEditOutputs.create, {...});
            
            // Remove from pending (triggers subscription)
            await ctx.runMutation(internal.imageEditTurns.removeFromPending, {
                id: turnId,
                model,
            });
        } catch (err) {
            // Still remove from pending on failure
            await ctx.runMutation(internal.imageEditTurns.removeFromPending, {...});
        }
    })
);
```

---

## Frontend Implementation

### File Structure

```
src/lib/components/studio/
  EditImageModal.svelte       # Modal to start new conversation
  TurnCard.svelte             # Single turn display
  ConversationHeader.svelte   # Header with back button, title, turn count

src/routes/posts/edit/
  [conversationId]/
    +page.svelte              # Main conversation page
```

### 1. Edit Button on Image Thumbnails

Add to `/posts/create/+page.svelte` in the thumbnail rendering:

```svelte
<button
    onclick={() => openEditModal(image)}
    class="absolute top-1 right-1 opacity-0 group-hover:opacity-100 ..."
>
    Edit
</button>
```

### 2. `EditImageModal.svelte`

**Props:**
```typescript
interface Props {
    image: GeneratedImage; // Source image to edit
    open: boolean;
    onclose: () => void;
}
```

**Layout (matching reference Image 1):**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â† New Conversation                                   â”‚
â”‚   Start editing this image                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    What would you like to change? â”‚
â”‚  â”‚              â”‚    Describe the edit you want...   â”‚
â”‚  â”‚   [IMAGE]    â”‚                                    â”‚
â”‚  â”‚              â”‚    [Models â–¼] [Model] Ã— [Model] Ã—  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                    â”‚
â”‚   Model Name                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚   1024 x 1024                â”‚ Your instructions  â”‚  â”‚
â”‚                              â”‚                    â”‚  â”‚
â”‚                              â”‚ ğŸ“ Add references  â”‚  â”‚
â”‚                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                      â”‚
â”‚                     [Cmd + Enter to send]  [â–¶ Start] â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**State:**
```typescript
let selectedModels = $state([props.image.model]); // Default to source model
let editPrompt = $state("");
let referenceImages = $state<File[]>([]);
let isStarting = $state(false);
```

**On Submit:**
```typescript
async function handleStart() {
    isStarting = true;
    const result = await client.action(api.ai.imageEdit.startConversation, {
        sourceImageId: image._id,
        userMessage: editPrompt,
        selectedModels,
        ...(referenceStorageIds.length && { manualReferenceIds: referenceStorageIds }),
    });
    goto(`/posts/edit/${result.conversationId}`);
}
```

### 3. Conversation Page (`/posts/edit/[conversationId]/+page.svelte`)

**Layout (matching reference Image 2):**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â† Gallery â”‚ Conversation Title              2 turns â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ [img1] [img2] [img3] [img4] ...     (thumbnail strip)â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                      â”‚
â”‚ â— EDIT 1                                             â”‚
â”‚   Replace the sea lion with a corgi                  â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”                                   â”‚
â”‚   â”‚     â”‚ â”‚ â—‹   â”‚ â† loading skeleton                â”‚
â”‚   â”‚img1 â”‚ â”‚Gen..â”‚                                   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜                                   â”‚
â”‚   SeeDream                                           â”‚
â”‚                                                      â”‚
â”‚ â— EDIT 2                                             â”‚
â”‚   Make the background sunset                         â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”                          â”‚
â”‚   â”‚     â”‚ â”‚     â”‚ â”‚     â”‚                          â”‚
â”‚   â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜                          â”‚
â”‚                                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ [Models â–¼] [Nano Pro Ã—] [SeeDream Ã—]                â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚ â”‚ Describe your edit...                          â”‚  â”‚
â”‚ â”‚ ğŸ“ References                                  â”‚  â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                              [Cmd+Enter]      [â–¶]   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Subscriptions:**
```typescript
// URL param
const conversationId = $derived($page.params.conversationId as Id<"image_edit_conversations">);

// Conversation metadata
const conversationQuery = useQuery(
    api.imageEditConversations.get,
    () => conversationId ? { id: conversationId } : "skip"
);

// All turns with their outputs
const turnsQuery = useQuery(
    api.imageEditTurns.listByConversation,
    () => conversationId ? { conversationId } : "skip"
);

// All outputs for thumbnail strip
const allOutputsQuery = useQuery(
    api.imageEditOutputs.listByConversation,
    () => conversationId ? { conversationId } : "skip"
);
```

**State:**
```typescript
let selectedModels = $state<string[]>(["google/gemini-3-pro-image-preview"]);
let editPrompt = $state("");
let referenceFiles = $state<File[]>([]);
let isSending = $state(false);
```

**Send Edit:**
```typescript
async function handleSendEdit() {
    if (!editPrompt.trim()) return;
    isSending = true;
    
    // Upload manual references if any
    const manualReferenceIds = await uploadReferences(referenceFiles);
    
    await client.action(api.ai.imageEdit.sendEdit, {
        conversationId,
        userMessage: editPrompt,
        selectedModels,
        ...(manualReferenceIds.length && { manualReferenceIds }),
    });
    
    editPrompt = "";
    referenceFiles = [];
    isSending = false;
}
```

### 4. `TurnCard.svelte`

**Props:**
```typescript
interface Props {
    turn: Turn;
    outputs: Output[];
    turnNumber: number; // 1-indexed for display
}
```

**Template:**
```svelte
<div class="space-y-3">
    <div class="flex items-center gap-2">
        <div class="h-2 w-2 rounded-full bg-primary"></div>
        <span class="text-xs text-muted-foreground">EDIT {turnNumber}</span>
    </div>
    <p class="text-sm">{turn.userMessage}</p>
    <div class="flex gap-3 flex-wrap">
        {#each outputs as output}
            <ImageThumbnail {output} />
        {/each}
        {#each turn.pendingModels ?? [] as model}
            <ImageSkeleton {model} size="thumbnail" />
        {/each}
    </div>
</div>
```

---

## Implementation Order

### Phase 1: Schema & Backend CRUD
1. Add new tables to `schema.ts`
2. Create `imageEditConversations.ts` with queries/mutations
3. Create `imageEditTurns.ts` with queries/mutations
4. Create `imageEditOutputs.ts` with queries/mutations
5. Run `bunx convex dev --once` to deploy

### Phase 2: Backend Actions
1. Create `ai/imageEdit.ts` with `startConversation` action
2. Add `sendEdit` action
3. Test with Convex dashboard

### Phase 3: Frontend Modal
1. Create `EditImageModal.svelte`
2. Add Edit button to image thumbnails in create page
3. Wire up modal open/close + navigation

### Phase 4: Conversation Page
1. Create route structure `/posts/edit/[conversationId]/`
2. Implement subscriptions and basic layout
3. Add `TurnCard.svelte` component
4. Implement send edit flow

### Phase 5: Polish
1. Add thumbnail strip for all conversation images
2. Handle errors and loading states
3. Add keyboard shortcut (Cmd+Enter to send)

---

## Files to Create/Modify

### New Files
| File | Purpose |
|------|---------|
| `src/convex/imageEditConversations.ts` | Conversation CRUD |
| `src/convex/imageEditTurns.ts` | Turn CRUD + progressive loading |
| `src/convex/imageEditOutputs.ts` | Output queries |
| `src/convex/ai/imageEdit.ts` | Generation actions |
| `src/lib/components/studio/EditImageModal.svelte` | Start conversation modal |
| `src/lib/components/studio/TurnCard.svelte` | Turn display component |
| `src/routes/posts/edit/[conversationId]/+page.svelte` | Conversation page |

### Modified Files
| File | Changes |
|------|---------|
| `src/convex/schema.ts` | Add 3 new tables |
| `src/routes/posts/create/+page.svelte` | Add Edit button on thumbnails |
| `src/lib/components/studio/index.ts` | Export new components |

---

## Verification

1. **Schema**: `bunx convex dev --once` - no errors
2. **Type Check**: `bun run check` - passes
3. **E2E Test Flow**:
   - Generate a post with images
   - Click Edit on a thumbnail â†’ modal opens
   - Enter edit prompt, select models, click Start
   - Redirected to conversation page
   - See turn 1 with loading skeletons â†’ images appear progressively
   - Send another edit â†’ turn 2 appears with progressive loading
   - Refresh page â†’ conversation history persists
   - Back button returns to create page

---

# ARCHIVED: Progressive Loading UI (Previous Plan)

The following was the previous plan for progressive loading, which has been implemented.

---

# Progressive Loading UI with Convex Subscriptions

## Goal

Replace the "all-at-once" loading with progressive UI updates:
1. **Caption loads first** â†’ show it immediately
2. **First image loads** â†’ mount the full results UI  
3. **Remaining images** â†’ show loading skeletons that fill in progressively
4. **Tooltip on loading skeletons** â†’ "Nao se preocupe, isso leva alguns segundos"

## Architecture

### Current Flow (synchronous)
```
Frontend calls action â†’ waits 30-60s â†’ gets all results at once
```

### New Flow (progressive with subscriptions)
```
Frontend calls action â†’ gets generatedPostId immediately
Frontend subscribes to:
  - generatedPosts.get(id) â†’ caption updates in real-time
  - generatedImages.listByPost(id) â†’ images appear as they complete
Backend updates DB progressively â†’ subscriptions push updates to frontend
```

---

## Files to Modify

| File | Changes |
|------|---------|
| `src/convex/schema.ts` | Add `pendingImageModels`, `totalImageModels` fields to `generated_posts` |
| `src/convex/generatedPosts.ts` | Add `removeFromPending` mutation, update `create` mutation args |
| `src/convex/ai/chat.ts` | Restructure to update DB progressively during generation |
| `src/routes/posts/create/+page.svelte` | Use `useQuery` subscriptions instead of waiting for action |
| `src/lib/components/studio/ImageSkeleton.svelte` | **NEW** - Loading skeleton with tooltip |

---

## Implementation Details

### 1. Update Schema (`src/convex/schema.ts`)

Add to `generated_posts` table definition (around line 62-98):

```typescript
// Add these fields after line 81 (after status field):
pendingImageModels: v.optional(v.array(v.string())), // Models still generating
totalImageModels: v.optional(v.number()), // Total models requested
```

### 2. Update `generatedPosts.ts` 

#### 2a. Update `create` mutation args (line 120-143)

Add new args:
```typescript
pendingImageModels: v.optional(v.array(v.string())),
totalImageModels: v.optional(v.number()),
```

Add to insert:
```typescript
...(args.pendingImageModels && { pendingImageModels: args.pendingImageModels }),
...(args.totalImageModels && { totalImageModels: args.totalImageModels }),
```

#### 2b. Add new `removeFromPending` mutation (after `updateFromChat`)

```typescript
// Remove a model from pending list (called when image generation completes)
export const removeFromPending = mutation({
    args: {
        id: v.id("generated_posts"),
        model: v.string(),
    },
    handler: async (ctx, args) => {
        const identity = await ctx.auth.getUserIdentity();
        if (!identity) {
            throw new Error("Not authenticated");
        }

        const post = await ctx.db.get(args.id);
        if (!post) return;
        
        const pending = post.pendingImageModels?.filter(m => m !== args.model) ?? [];
        await ctx.db.patch(args.id, { 
            pendingImageModels: pending,
            updatedAt: Date.now(),
        });
    },
});
```

#### 2c. Update `updateFromChat` mutation to support clearing `pendingImageModels`

Add to args:
```typescript
pendingImageModels: v.optional(v.array(v.string())),
totalImageModels: v.optional(v.number()),
```

Add to patch:
```typescript
...(args.pendingImageModels !== undefined && { pendingImageModels: args.pendingImageModels }),
...(args.totalImageModels !== undefined && { totalImageModels: args.totalImageModels }),
```

### 3. Restructure `generate` Action (`src/convex/ai/chat.ts`)

Key changes:
1. Create post immediately with `status: "generating_caption"` and `pendingImageModels`
2. Update caption to DB BEFORE starting image generation
3. Each image saves individually (already does this)
4. Remove from `pendingImageModels` as each completes
5. Return `generatedPostId` at the end (action still runs to completion, but subscriptions provide live updates)

```typescript
export const generate = action({
    // ... existing args
    handler: async (ctx, args): Promise<{
        success: boolean;
        generatedPostId: Id<"generated_posts">;
    }> => {
        // 1. Auth check (existing)
        
        // 2. Verify project access (existing)
        
        // 3. Parse studio settings (existing)
        const imageModels = args.imageModels ?? [DEFAULT_IMAGE_MODEL];
        
        // 4. Create post with progressive state
        const generatedPostId = await ctx.runMutation(api.generatedPosts.create, {
            ...(args.projectId && { projectId: args.projectId }),
            caption: "", // Will be updated
            status: "generating_caption",
            pendingImageModels: imageModels,
            totalImageModels: imageModels.length,
        });

        // 5. Save user message (existing)

        // 6. Generate caption
        const captionResult = await generateCaption({...});
        
        // 7. Update post with caption, change status to "generating_images"
        await ctx.runMutation(api.generatedPosts.updateFromChat, {
            id: generatedPostId,
            caption: captionResult.caption,
            model: MODELS.GPT_4_1,
            status: "generating_images",
        });

        // 8. Collect reference images (existing)

        // 9. Generate images in parallel
        await Promise.all(
            imageModels.map(async (model) => {
                try {
                    const imageResult = await generateImage({...});
                    
                    // Store and save to DB (existing logic)
                    const storageId = await ctx.storage.store(blob);
                    await ctx.runMutation(api.generatedImages.create, {...});
                    
                    // Remove from pending
                    await ctx.runMutation(api.generatedPosts.removeFromPending, {
                        id: generatedPostId,
                        model,
                    });
                } catch (err) {
                    console.error(`Image generation failed for ${model}:`, err);
                    // Still remove from pending on failure
                    await ctx.runMutation(api.generatedPosts.removeFromPending, {
                        id: generatedPostId,
                        model,
                    });
                }
            })
        );

        // 10. Get results for primary image (for backward compatibility)
        const allImages = await ctx.runQuery(api.generatedImages.listByPost, {
            generatedPostId,
        });
        const primaryImage = allImages[0];

        // 11. Mark as completed with final state
        await ctx.runMutation(api.generatedPosts.updateFromChat, {
            id: generatedPostId,
            ...(primaryImage && { imageStorageId: primaryImage.storageId }),
            ...(primaryImage && { imagePrompt: primaryImage.prompt }),
            ...(primaryImage && { imageModel: primaryImage.model }),
            status: "generated",
            pendingImageModels: [], // Clear pending
        });

        // 12. Save assistant message (existing)

        return {
            success: true,
            generatedPostId,
        };
    },
});
```

### 4. Frontend Progressive UI (`+page.svelte`)

#### 4a. Update imports and state

```typescript
import { useConvexClient, useQuery } from "convex-svelte";

// Add new state for progressive loading
let generatedPostId = $state<Id<"generated_posts"> | null>(null);

// Subscriptions using "skip" pattern for conditional queries
const postQuery = useQuery(
    api.generatedPosts.get, 
    () => generatedPostId ? { id: generatedPostId } : "skip"
);

const imagesQuery = useQuery(
    api.generatedImages.listByPost,
    () => generatedPostId ? { generatedPostId } : "skip"
);

// Derived states from subscriptions
let postData = $derived(postQuery.data);
let imagesData = $derived(imagesQuery.data ?? []);

// Progressive loading states
let isGeneratingCaption = $derived(postData?.status === "generating_caption");
let isGeneratingImages = $derived(postData?.status === "generating_images");
let isCompleted = $derived(postData?.status === "generated");
let caption = $derived(postData?.caption ?? "");
let pendingModels = $derived(postData?.pendingImageModels ?? []);
let totalModels = $derived(postData?.totalImageModels ?? selectedModels.length);
let hasAnyImage = $derived(imagesData.length > 0);
let hasCaption = $derived(caption.length > 0);

// Update generatedCaption/generatedImages for existing UI
$effect(() => {
    if (postData?.caption) {
        generatedCaption = postData.caption;
    }
});

$effect(() => {
    if (imagesData.length > 0) {
        generatedImages = imagesData.map(img => ({
            storageId: img.storageId,
            model: img.model,
            url: img.url,
            prompt: img.prompt,
            width: img.width,
            height: img.height,
        }));
    }
});
```

#### 4b. Update `handleGenerate` function

```typescript
async function handleGenerate() {
    if (!prompt.trim()) return;
    
    isGenerating = true;
    error = null;
    hasGenerated = false;
    generatedPostId = null; // Reset
    
    try {
        // Upload reference images (existing)
        let imageStorageIds: Id<"_storage">[] = [];
        if (referenceImages.length > 0) {
            const uploadPromises = referenceImages.map(img => uploadFileToStorage(img.file));
            imageStorageIds = await Promise.all(uploadPromises);
        }

        const attachments = imageStorageIds.length > 0 
            ? { imageStorageIds } 
            : undefined;

        // Call action - returns immediately with generatedPostId
        const result = await client.action(api.ai.chat.generate, {
            message: buildFullPrompt(),
            imageModels: selectedModels,
            aspectRatio,
            resolution,
            ...(attachments && { attachments }),
        });

        // Set ID to start subscriptions
        generatedPostId = result.generatedPostId;
        hasGenerated = true;
        
    } catch (err) {
        console.error("Generation failed:", err);
        error = err instanceof Error ? err.message : "Erro ao gerar conteudo";
        isGenerating = false;
    }
}
```

#### 4c. Update effect to track completion

```typescript
// Track when generation is complete
$effect(() => {
    if (isCompleted && generatedPostId) {
        isGenerating = false;
    }
});
```

#### 4d. Update UI states in template

Replace the loading/results section with progressive states:

```svelte
{#if error && !isGenerating}
    <!-- Error state (existing) -->

{:else if !hasGenerated && !isGenerating && !generatedPostId}
    <!-- Empty state (existing) -->

{:else if isGenerating && !generatedPostId}
    <!-- Initial loading - uploading references -->
    <div class="flex flex-1 flex-col items-center justify-center gap-4 p-8">
        <LoadingSpinner />
        <div class="text-center">
            <h3 class="text-lg font-medium">Iniciando geracao</h3>
            <p class="mt-2 text-xs text-muted-foreground">
                Preparando arquivos...
            </p>
        </div>
    </div>

{:else if generatedPostId && isGeneratingCaption}
    <!-- Caption loading -->
    <div class="flex flex-1 flex-col items-center justify-center gap-4 p-8">
        <LoadingSpinner />
        <div class="text-center">
            <h3 class="text-lg font-medium">Gerando legenda</h3>
            <p class="mt-2 text-xs text-muted-foreground">
                Criando uma legenda perfeita para seu post...
            </p>
        </div>
    </div>

{:else if generatedPostId && hasCaption}
    <!-- Results UI - show progressively -->
    <div class="flex flex-1 overflow-hidden">
        <!-- Image section -->
        <div class="flex flex-1 flex-col border-r border-border">
            <div class="flex items-center justify-between border-b border-border bg-background px-4 py-3">
                <div class="flex items-center gap-2">
                    <h3 class="text-sm font-medium">Imagens Geradas</h3>
                    {#if !hasAnyImage}
                        <Badge variant="secondary">Gerando...</Badge>
                    {:else}
                        <Badge variant="secondary">{imagesData.length}/{totalModels}</Badge>
                    {/if}
                </div>
                <!-- ... existing buttons ... -->
            </div>
            
            <div class="flex flex-1 flex-col overflow-auto bg-muted/50">
                {#if !hasAnyImage}
                    <!-- No images yet - show all skeletons -->
                    <div class="grid grid-cols-2 gap-4 p-6">
                        {#each selectedModels as model}
                            <ImageSkeleton {model} aspectRatio={aspectRatio} />
                        {/each}
                    </div>
                {:else}
                    <!-- Show images + pending skeletons -->
                    <div class="flex flex-1 flex-col">
                        <!-- Main selected image (existing) -->
                        
                        <!-- Thumbnail strip with skeletons for pending -->
                        <div class="shrink-0 border-t border-border bg-background p-4">
                            <div class="flex justify-center gap-3">
                                {#each generatedImages as image, index}
                                    <!-- Existing thumbnail buttons -->
                                {/each}
                                {#each pendingModels as model}
                                    <ImageSkeleton {model} size="thumbnail" />
                                {/each}
                            </div>
                        </div>
                    </div>
                {/if}
            </div>
        </div>

        <!-- Caption section (existing, but shows immediately when ready) -->
    </div>
{/if}
```

### 5. Create ImageSkeleton Component

Create `src/lib/components/studio/ImageSkeleton.svelte`:

```svelte
<script lang="ts">
    import { Tooltip, TooltipTrigger, TooltipContent, TooltipProvider } from "$lib/components/ui";
    
    interface Props {
        model?: string;
        aspectRatio?: string;
        size?: "full" | "thumbnail";
    }
    
    let { model, aspectRatio = "1:1", size = "full" }: Props = $props();
    
    // Model name mapping for display
    const modelDisplayNames: Record<string, string> = {
        "google/gemini-2.5-flash-image": "Nano Banana",
        "google/gemini-3-pro-image-preview": "Nano Banana Pro",
        "bytedance-seed/seedream-4.5": "SeeDream v4.5",
        "black-forest-labs/flux.2-flex": "Flux 2 Flex",
        "openai/gpt-5-image": "GPT Image 1.5",
    };
    
    let displayName = $derived(modelDisplayNames[model ?? ""] ?? model?.split("/").pop() ?? "");
    
    // Parse aspect ratio for styling
    let [w, h] = $derived(aspectRatio.split(":").map(Number));
</script>

<TooltipProvider>
    <Tooltip>
        <TooltipTrigger asChild>
            {#if size === "thumbnail"}
                <div 
                    class="group relative h-20 w-20 overflow-hidden border-2 border-dashed border-border bg-muted animate-pulse"
                >
                    <div class="absolute inset-0 flex flex-col items-center justify-center gap-1">
                        <svg class="h-4 w-4 animate-spin text-muted-foreground" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24">
                            <circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle>
                            <path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path>
                        </svg>
                    </div>
                    <div class="absolute inset-x-0 bottom-0 bg-black/70 px-1 py-0.5 text-center text-[10px] text-white opacity-0 transition-opacity group-hover:opacity-100">
                        {displayName}
                    </div>
                </div>
            {:else}
                <div 
                    class="relative overflow-hidden border border-dashed border-border bg-muted animate-pulse"
                    style="aspect-ratio: {w} / {h};"
                >
                    <div class="absolute inset-0 flex flex-col items-center justify-center gap-3">
                        <svg class="h-8 w-8 animate-spin text-muted-foreground" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24">
                            <circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle>
                            <path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path>
                        </svg>
                        {#if model}
                            <span class="text-xs text-muted-foreground">{displayName}</span>
                        {/if}
                    </div>
                </div>
            {/if}
        </TooltipTrigger>
        <TooltipContent>
            <p>Nao se preocupe, isso leva alguns segundos</p>
        </TooltipContent>
    </Tooltip>
</TooltipProvider>
```

### 6. Export ImageSkeleton from studio index

Update `src/lib/components/studio/index.ts`:

```typescript
export { default as ImageSkeleton } from "./ImageSkeleton.svelte";
```

---

## Verification

1. `bun run check` - no TypeScript errors
2. `bunx convex dev --once` - deploy backend changes
3. Test generation flow:
   - [ ] Caption should appear within 5-10s
   - [ ] First image should appear 10-20s after caption
   - [ ] Remaining images fill in progressively
   - [ ] Skeletons show tooltip on hover
4. Test with multiple models selected
5. Test error handling (one model fails, others succeed)
6. Test page refresh during generation (should see current state)

---

## Edge Cases

| Case | Expected Behavior |
|------|-------------------|
| User navigates away | Subscriptions clean up automatically, action continues in background |
| All images fail | Show caption + "Nenhuma imagem foi gerada" |
| Network disconnect | Convex reconnects automatically, subscriptions resume |
| Page refresh mid-generation | Re-subscribe, see current state from DB |
| Caption generation fails | Show error, don't proceed to images |

---

## Order of Implementation

1. Schema changes (`schema.ts`)
2. Add `removeFromPending` mutation (`generatedPosts.ts`)
3. Update `create` and `updateFromChat` args (`generatedPosts.ts`)
4. Create `ImageSkeleton.svelte` component
5. Export from studio index
6. Restructure `generate` action (`chat.ts`)
7. Update frontend page (`+page.svelte`)
8. Test and verify
